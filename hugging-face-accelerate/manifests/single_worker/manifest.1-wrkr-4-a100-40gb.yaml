# This manifest run the training with:
# - 1 container
# - 4 NVIDIA-A100-SXM4-40GB GPU per container (1*4=4GPUs)
#
# - mixed_precision bf16
# - batch_size 40
# - epochs 12
# - model: tinyllama
# Execution time: 1m54s.

kind: AIchorManifest
apiVersion: 0.2.2

builder:
  image: image
  context: hugging-face-accelerate # hugging-face-accelerate folder
  dockerfile: ./Dockerfile

spec:
  operator: pytorch
  image: image
  command: "torchrun --nproc_per_node 4 main.py --mixed_precision bf16 --batch_size=40" # --nproc_per_node=={Number of GPUs}

  tensorboard:
    enabled: true

  types:
    Worker:
      count: 1
      resources:
        cpus: 4
        ramRatio: 8 # 32GB
        accelerators: # optional
          gpu:
            count: 4 # note that setting more than 1 MIG device per container is useless since only one will be usable https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-device-enumeration
            type: gpu
            product: NVIDIA-A100-SXM4-40GB

