# This manifest run the training with:
# - 1 container
# - 8 NVIDIA-A100-SXM4-40GB GPU per container (1*8=8GPUs)
#
# - mixed_precision bf16
# - batch_size 40
# - epochs 12
# - model: tinyllama
# Execution time: 1m9s.

kind: AIchorManifest
apiVersion: 0.2.2

builder:
  image: image
  context: hugging-face-accelerate # hugging-face-accelerate folder
  dockerfile: ./Dockerfile

spec:
  operator: pytorch
  image: image
  command: "torchrun --nproc_per_node 8 main.py --mixed_precision bf16 --batch_size=40" # --nproc_per_node=={Number of GPUs}

  tensorboard:
    enabled: true

  types:
    Worker:
      count: 1
      resources:
        cpus: 8
        ramRatio: 4 # 32GB
        accelerators: # optional
          gpu:
            count: 8 # note that setting more than 1 MIG device per container is useless since only one will be usable https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-device-enumeration
            type: gpu
            product: NVIDIA-A100-SXM4-40GB

